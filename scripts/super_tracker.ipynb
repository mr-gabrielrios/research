{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "474cadb8-c900-4e4f-be72-3be8bf7af9ef",
   "metadata": {},
   "source": [
    "### TC super tracker\n",
    "__Objective__: this script is intended to leverage `tc_analysis.tc_track_data` for multiple models and experiments and save data, to avoid repeated loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f01f61fd-6033-45f3-80ab-4e80c74eb89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "import tc_analysis, visualization, utilities\n",
    "\n",
    "importlib.reload(tc_analysis);\n",
    "importlib.reload(utilities);\n",
    "importlib.reload(visualization);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "707403c3-02fd-4933-8852-84d67d9157cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_experiments(root_dirname: str='/projects/GEOCLIM/gr7610/MODEL_OUT',\n",
    "                     maximum_year_length: int=200) -> dict:\n",
    "\n",
    "    ''' \n",
    "    Crawler method that goes through the root directory `root_dirname` and finds experiments with TC tracks.\n",
    "    The output will be inputs for the tc_analysis.tc_track_data method.\n",
    "\n",
    "    Arguments:\n",
    "    - root_dirname: parent directory from which experiments in subdirectories will be found.\n",
    "    - maximum_year_length: maximum number of years that track data can be loaded for.\n",
    "    Returns:\n",
    "    - track_names: multi-level dictionary that provides inputs for the track data parser method. Dictionary structure below:\n",
    "\n",
    "    Example:\n",
    "    - track_names = {'model_name': {'experiment_name': (minimum_year, maximum_year)}}\n",
    "    '''\n",
    "\n",
    "    # Define strings corresponding to TC tracking algorithm subdirectories\n",
    "    track_directory_identifier = 'analysis_lmh'\n",
    "    track_subdirectory_identifier = 'cyclones_gav'\n",
    "    \n",
    "    # Specify substrings that belong to experiments that TC tracks shouldn't be processed for\n",
    "    ignore_identifiers = ['8xdaily']\n",
    "\n",
    "    # Initialize the dictionary\n",
    "    track_names = {}\n",
    "    # Search through the root directory provided\n",
    "    for model_name in os.listdir(root_dirname):\n",
    "        # Get pathname, save to check if it's a directory. Assume the pathname is a model.\n",
    "        model_pathname = os.path.join(root_dirname, model_name)\n",
    "        # If the path is a directory, assume it's a model. \n",
    "        # Step into it and search through model subdirectories\n",
    "        if os.path.isdir(model_pathname):\n",
    "            track_names[model_name] = {}\n",
    "            # Iterate over assumed model directories\n",
    "            for experiment_name in os.listdir(model_pathname):\n",
    "                # Ignore files with specific identifiers in the name\n",
    "                ignore_boolean = sum([identifier in experiment_name for identifier in ignore_identifiers])\n",
    "                \n",
    "                # Get pathname, save to check if it's a directory\n",
    "                experiment_pathname = os.path.join(model_pathname, experiment_name)\n",
    "                # If the path is a directory, assume it's an experiment. \n",
    "                # Step into it and search through experiment subdirectories\n",
    "                if os.path.isdir(experiment_pathname) and ignore_boolean == 0:\n",
    "                    # Search through experiment subdirectories\n",
    "                    for experiment_subdirectory_name in os.listdir(experiment_pathname):\n",
    "                        track_directory = os.path.join(experiment_pathname, experiment_subdirectory_name)\n",
    "                        # The track directory should be an experiment subdirectory. \n",
    "                        # Check here for a subdirectory or symbolic link that matches the identifier.\n",
    "                        if (os.path.isdir(track_directory) or (os.path.islink(track_directory))) and experiment_subdirectory_name == track_directory_identifier:\n",
    "                            for track_subdirectory_name in os.listdir(track_directory):\n",
    "                                # Make sure identified subdirectory is a parent directory for tracked TC data.\n",
    "                                if track_subdirectory_identifier in track_subdirectory_name:\n",
    "                                    track_subdirectory = os.path.join(track_directory, track_subdirectory_name)\n",
    "                                    # Get minimum and maximum years in the listed track data\n",
    "                                    track_year_range = [int(f.split('_')[-1]) for f in os.listdir(track_subdirectory)]\n",
    "                                    # Make sure year range isn't too long, redefine lengths based on model type\n",
    "                                    if (max(track_year_range) - min(track_year_range)) > maximum_year_length:\n",
    "                                        track_year_range = (2001, 2200) if model_name == 'FLOR' else (101, 300)\n",
    "                                    # Assign year range to the model and experiment configuration entry\n",
    "                                    track_names[model_name][experiment_name] = (min(track_year_range), max(track_year_range))\n",
    "\n",
    "    return track_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b524c8c-9265-4779-acec-b2e8bff6ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tracks(model_name: str,\n",
    "                experiment_name: str,\n",
    "                year_range: tuple[int, int],\n",
    "                track_dataset: dict,\n",
    "                root_dirname: str='/projects/GEOCLIM/gr7610/analysis/tc_storage/track_data',\n",
    "                overwrite: bool=False):\n",
    "\n",
    "    filename = f'TC_track_data.s{min(year_range)}_e{max(year_range)}.model_{model_name}.experiment_{experiment_name}.pkl'\n",
    "    pathname = os.path.join(root_dirname, filename)\n",
    "\n",
    "    if os.path.isfile(pathname) and not overwrite:\n",
    "        print(f'Data already exists for {pathname}. Please set the `overwrite` argument to `True` if you wish to overwrite this file.')\n",
    "    else:\n",
    "        with open(pathname, 'wb') as f:\n",
    "            pickle.dump(track_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82312794-a840-4bb1-9b3c-7d21942ee37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(track_names: dict) -> dict:\n",
    "\n",
    "    '''\n",
    "    Method that loads TC track data given a dictionary with track names output by `find_experiments()`.\n",
    "    '''\n",
    "    \n",
    "    track_datasets = {}\n",
    "    for model in track_names.keys():\n",
    "        track_datasets[model] = {}\n",
    "        for experiment in track_names[model].keys():\n",
    "            year_range = track_names[model][experiment]\n",
    "            print(f'[load()] Model {model}; experiment {experiment}; year range = {year_range}')\n",
    "    \n",
    "            track_datasets[model][experiment] = tc_analysis.tc_track_data(models=[model], \n",
    "                                                                          experiments=[experiment], \n",
    "                                                                          year_range=year_range, \n",
    "                                                                          storm_type='TS',\n",
    "                                                                          parallel_load=True)\n",
    "\n",
    "            save_tracks(model_name=model,\n",
    "                        experiment_name=experiment,\n",
    "                        year_range=year_range,\n",
    "                        track_dataset=track_datasets[model][experiment])            \n",
    "\n",
    "    return track_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc1ca9fa-665c-493a-90e7-822aed903b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    track_names = find_experiments()\n",
    "    track_datasets = load(track_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42034ea6-09c6-419e-a628-5ccec2c4609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load()] Model AM2.5; experiment CTL1990s; year range = (101, 300)\n",
      "[tc_track_data] Checkpoint 0: 0.000 s elapsed\n",
      "[tc_track_data] working on tracks for configuration: AM2.5, CTL1990s\n",
      "[tc_track_data] Checkpoint 1: 0.000 s elapsed\n",
      "[tc_track_data] Checkpoint 2: 16.640 s elapsed\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1ba92f-43ea-48cc-bc05-e90bfc2b9b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
