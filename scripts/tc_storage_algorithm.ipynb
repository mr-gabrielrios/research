{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c07d45bf-dfcf-416b-8fa3-32ece4e664be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' Import packages. '''\n",
    "# Time packages\n",
    "import cftime, datetime, time\n",
    "# Numerical analysis packages\n",
    "import numpy as np, random, scipy\n",
    "# Local data storage packages\n",
    "import dill, os, pickle\n",
    "# Data structure packages\n",
    "import pandas as pd, xarray as xr\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bfbc3dc-217d-4eea-a6c6-2683781723cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tc_storage(model, experiment, year_range, storm_type, benchmarking=True):\n",
    "    \n",
    "    ''' \n",
    "    Function to build unified xArray Dataset to hold model and track data for tracked TCs in a given model and experiment.\n",
    "    \n",
    "    Input(s):\n",
    "    - model (str):                name of model to access (typically \"AM2.5\" or \"HIRAM\")\n",
    "    - experiment (str):           name of experiment to access (typically \"control\", \"ktc\", \"plus2K\", etc.)\n",
    "    - year_range (tuple of ints): 2-element tuple with a start and end year\n",
    "    - storm_type (str):           type of storm to evaluate from TC tracks data (\"TS\" for all storms or \"C15w\" for hurricanes)\n",
    "    - benchmarking (bool):        boolean to enable time benchmarking\n",
    "    Output(s):\n",
    "    - dirs (tuple):               2-element tuple with pathnames for the model- and experiment-specific GCM and track directories.\n",
    "    '''\n",
    "    \n",
    "    # Define paths to model- and experiment-specific data\n",
    "    model_dir, track_dir = dirnames(model, experiment)\n",
    "    # Define date range\n",
    "    date_range = [cftime.DatetimeNoLeap(year=year, month=1, day=1, hour=0) for year in range(min(year_range), max(year_range))]\n",
    "    # Iterate over years. This is performed because data is saved into year-specific files.\n",
    "    for year in date_range:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969fb8ac-4279-481e-bceb-0f0065cdaf44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dirnames(model, experiment):\n",
    "\n",
    "    ''' \n",
    "    Function to store pathnames for selected models and experiments. \n",
    "    \n",
    "    Input(s):\n",
    "    - model (str):  name of model to access (typically \"AM2.5\" or \"HIRAM\").\n",
    "    Output(s):\n",
    "    - dirs (tuple): 2-element tuple with pathnames for the model- and experiment-specific GCM and track directories.\n",
    "    '''\n",
    "    \n",
    "    # Define experiment-specific pathnames\n",
    "    experiments = {'control': {'AM2.5': 'CTL1990s_tigercpu_intelmpi_18_540PE',\n",
    "                               'HIRAM': 'CTL1990s_v201910_tigercpu_intelmpi_18_540PE'},\n",
    "                   'ktc': {'AM2.5': 'CTL1990s_killtc13-13-15_tigercpu_intelmpi_18_540PE',\n",
    "                           'HIRAM': 'CTL1990s_v201910_killtc13-13-15_tigercpu_intelmpi_18_540PE'}}\n",
    "    # Model directories\n",
    "    model_dirs = {'AM2.5': {'control': '/tigress/wenchang/analysis/TC/AM2.5/CTL1990s_tigercpu_intelmpi_18_540PE/model_out/POSTP',\n",
    "                            'ktc': '/tigress/wenchang/analysis/TC/AM2.5ktc2/CTL1990s_killtc13-13-15_tigercpu_intelmpi_18_540PE/modelout/POSTP'},\n",
    "                  'HIRAM': {'control': '/tigress/wenchang/analysis/TC/HIRAM/CTL1990s_v201910_tigercpu_intelmpi_18_540PE/model_out/POSTP',\n",
    "                            'ktc': '/tigress/wenchang/analysis/TC/HIRAMktc2/CTL1990s_v201910_killtc13-13-15_tigercpu_intelmpi_18_540PE/modelout/POSTP'}}\n",
    "    # Track directories\n",
    "    # Potential issue: ask Wenchang about using track .nc files in the same parent directory tree as the model data\n",
    "    track_dirs = {'AM2.5': {'control': '/tigress/wenchang/MODEL_OUT/AM2.5/CTL1990s_tigercpu_intelmpi_18_540PE/analysis_lmh/cyclones_gav_ro110_1C_330k',\n",
    "                            'ktc': '/tigress/wenchang/MODEL_OUT/AM2.5ktc2/CTL1990s_killtc13-13-15_tigercpu_intelmpi_18_540PE/analysis_lmh/cyclones_gav_ro110_1C_330k'},\n",
    "                  'HIRAM': {'control': '/tigress/wenchang/MODEL_OUT/HIRAM/CTL1990s_v201910_tigercpu_intelmpi_18_540PE/analysis_lmh/cyclones_gav_ro110_2p5C_330k',\n",
    "                            'ktc': '/tigress/wenchang/MODEL_OUT/HIRAMktc2/CTL1990s_v201910_killtc13-13-15_tigercpu_intelmpi_18_540PE/analysis_lmh/cyclones_gav_ro110_1C_330k'}}\n",
    "\n",
    "    dirs = (model_dirs[model][experiment], track_dirs[model][experiment])\n",
    "    \n",
    "    return dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1bacb5f3-1e9a-45be-9b9b-77d094415a53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_tracked_TCs(dirname, storm_type, year_range):\n",
    "\n",
    "    '''\n",
    "    Function to collect tracked TC data and add derived data, such as duration and storm speed.\n",
    "    \n",
    "    Input(s):\n",
    "    - dirname (str):              name of directory containing files of interest\n",
    "    - storm_type (str):           type of storm to evaluate from TC tracks data (\"TS\" for all storms or \"C15w\" for hurricanes)\n",
    "    - year_range (tuple of ints): 2-element tuple with a start and end year\n",
    "    Output(s):\n",
    "    - data (Pandas DataFrame):    Pandas DataFrame with tracked TC data\n",
    "    '''\n",
    "    \n",
    "    ''' File collection. '''\n",
    "    # Get filenames for all files within the specified directory \n",
    "    # Filenames will correspond to the determined storm type\n",
    "    fnames = [[os.path.join(dirname, file, 'Harris.TC', f) for f in os.listdir(os.path.join(dirname, file, 'Harris.TC')) \n",
    "               if '{0}.world'.format(storm_type) in f]\n",
    "               for file in sorted(os.listdir(dirname))]\n",
    "    # Compress 2D list to 1D list\n",
    "    fnames = [item for sublist in fnames for item in sublist]\n",
    "\n",
    "    # Select files with dates within 'year_range'\n",
    "    # Note: the '+ 1900' is added because tracked TCs are on the 2000 year range, whereas model output is on the 100 year range\n",
    "    fnames = [f for f in fnames \n",
    "              if min(year_range) + 1900 <= pd.to_datetime(f.split('.')[-2].split('-')[0]).year < max(year_range) + 1900]\n",
    "    \n",
    "    # Concatenate all tracked TC data from the filename list\n",
    "    data = pd.concat([lmh_parser(os.path.join(dirname, fname)) for fname in fnames])\n",
    "\n",
    "    ''' Derived data algorithm. '''\n",
    "    # Initialize empty duration column to populate iteratively\n",
    "    data[['duration', 'velocity']] = np.nan\n",
    "    # Iterate through each unique storm (identify by 'storm_id') and get duration\n",
    "    for storm in data['storm_id'].unique():\n",
    "        # Get difference between minimum and maximum timestamps\n",
    "        dt = (data.loc[data['storm_id'] == storm]['time'].max() - data.loc[data['storm_id'] == storm]['time'].min())\n",
    "        # Convert difference timedelta into hours\n",
    "        dt = dt.days + dt.seconds/86400\n",
    "        # Add duration to the DataFrame for the corresponding storm\n",
    "        data.loc[data['storm_id'] == storm, 'duration'] = dt\n",
    "        \n",
    "    ''' Storm speed algorithm. '''\n",
    "    \n",
    "        \n",
    "    # Rename columns for future addition into xArray Dataset\n",
    "    data = data.rename(columns={'lon': 'center_lon', 'lat': 'center_lat', 'flag': 'core_temp', 'slp': 'min_slp'})\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d4303b6-d456-46b3-b84b-45090ebe2bd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lmh_parser(path):\n",
    "    \n",
    "    ''' \n",
    "    This method parses through text files from Lucas Harris' run outputs (held in directories titled 'analysis_lmh') \n",
    "    and produces an output DataFrame. \n",
    "    \n",
    "    Input(s):\n",
    "    - path (str):            path containing raw tracker data from Lucas Harris' runs.\n",
    "    Output(s):\n",
    "    - df (Pandas DataFrame): Pandas DataFrame containing tracked TC data\n",
    "    '''\n",
    "    \n",
    "    # Create file object instance\n",
    "    fobj = open(path, 'r').readlines()\n",
    "    # Initialize dictionary to hold data\n",
    "    data = {'storm_num': {}}\n",
    "    # Initialize storm counter\n",
    "    count = 1\n",
    "    # Iterate through text file\n",
    "    for line in fobj:\n",
    "        # Extract information from the line\n",
    "        content = line.strip()\n",
    "        # Creates new storm-specific dict in the parent dict. The '+++' demarcates a new storm.\n",
    "        if '+++' in line:\n",
    "            storm_num = '{0:04d}'.format(count)\n",
    "            data['storm_num'][storm_num] = {'storm_id': [], 'time': [], 'lon': [], 'lat': [], 'slp': [], 'max_wnd': [], 'flag': []}\n",
    "            count += 1\n",
    "        # Populates the storm-specific dict\n",
    "        else:\n",
    "            storm_num = '{0:04d}'.format(count-1) \n",
    "            tc_info = [x for x in content.split(' ') if x]\n",
    "            year = tc_info[0][0:4] # get 4-digit year\n",
    "            data['storm_num'][storm_num]['storm_id'].append('{0}-{1:04d}'.format(year, count-1))\n",
    "            data['storm_num'][storm_num]['time'].append(tc_info[0])\n",
    "            data['storm_num'][storm_num]['lon'].append(tc_info[1])\n",
    "            data['storm_num'][storm_num]['lat'].append(tc_info[2])\n",
    "            data['storm_num'][storm_num]['slp'].append(tc_info[3])\n",
    "            data['storm_num'][storm_num]['max_wnd'].append(tc_info[4])\n",
    "            data['storm_num'][storm_num]['flag'].append(tc_info[5])\n",
    "    \n",
    "    try:\n",
    "        # Converts the dictionary into a DataFrame\n",
    "        df = pd.concat({k: pd.DataFrame(v).T for k, v in data.items()}, axis=1)['storm_num']\n",
    "        df = df.explode(df.columns.to_list()).reset_index().rename(columns={'index': 'storm_num'})\n",
    "        # Re-cast column data types\n",
    "        df = df.astype({'lon': 'float', 'lat': 'float', 'slp': 'float', 'max_wnd': 'float', 'flag': 'float'})\n",
    "    except:\n",
    "        df = pd.DataFrame(columns=['storm_id', 'time', 'lon', 'lat', 'slp', 'max_wnd', 'flag'])\n",
    "    \n",
    "    ''' DataFrame refinement. '''\n",
    "    # Remove cold-core data points (flag == -1)\n",
    "    df = df.loc[df['flag'] != -1]\n",
    "    # Convert timestamps to datetime objects\n",
    "    df['time'] = pd.to_datetime(df['time'], format='%Y%m%d%H')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "76e43711-3711-4da6-a6c8-274a2c301b09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def coords_to_dist(a, b):\n",
    "    ''' Convert coordinates to distance in meters. '''\n",
    "    \n",
    "    R = 6371e3\n",
    "    \n",
    "    lon_a, lat_a = np.array(a)*np.pi/180\n",
    "    lon_b, lat_b = np.array(b)*np.pi/180\n",
    "    \n",
    "    dlon, dlat = lon_b - lon_a, lat_b - lat_a\n",
    "    \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat_a)*np.cos(lat_b)*np.sin(dlon/2)**2    \n",
    "    c = 2*np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    \n",
    "    distance = R*c\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "94aa2604-9a4d-4597-8181-ea8ca9805f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    storm_num   storm_id                time  center_lon  center_lat  min_slp  \\\n",
      "0        0001  2001-0001 2001-05-19 12:00:00      292.70       20.61  1005.16   \n",
      "2        0001  2001-0001 2001-05-20 00:00:00      292.25       21.64   998.55   \n",
      "3        0001  2001-0001 2001-05-20 06:00:00      291.91       22.53   995.11   \n",
      "4        0001  2001-0001 2001-05-20 12:00:00      291.71       23.09   996.21   \n",
      "5        0001  2001-0001 2001-05-20 18:00:00      291.40       23.78   994.34   \n",
      "..        ...        ...                 ...         ...         ...      ...   \n",
      "171      0003  2004-0003 2004-10-01 18:00:00      115.25       26.16  1006.58   \n",
      "172      0003  2004-0003 2004-10-02 00:00:00      115.09       27.03  1007.37   \n",
      "173      0003  2004-0003 2004-10-02 06:00:00      115.38       27.59  1005.68   \n",
      "174      0003  2004-0003 2004-10-02 12:00:00      115.43       27.96  1007.71   \n",
      "175      0003  2004-0003 2004-10-02 18:00:00      116.20       28.73  1008.63   \n",
      "\n",
      "     max_wnd  core_temp  duration  velocity  \n",
      "0      14.90     254.74      6.50       NaN  \n",
      "2      19.03     259.97      6.50       NaN  \n",
      "3      22.13     257.77      6.50       NaN  \n",
      "4      20.15     259.77      6.50       NaN  \n",
      "5      22.30     256.80      6.50       NaN  \n",
      "..       ...        ...       ...       ...  \n",
      "171     3.85     257.55     17.25       NaN  \n",
      "172     4.13     258.54     17.25       NaN  \n",
      "173     3.73     258.90     17.25       NaN  \n",
      "174     3.55     257.93     17.25       NaN  \n",
      "175     3.27     257.65     17.25       NaN  \n",
      "\n",
      "[590 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "dirname = '/tigress/wenchang/MODEL_OUT/HIRAMktc2/CTL1990s_v201910_killtc13-13-15_tigercpu_intelmpi_18_540PE/analysis_lmh/cyclones_gav_ro110_1C_330k'\n",
    "df = retrieve_tracked_TCs(dirname, 'C15w', year_range=(101, 105))\n",
    "print(df)\n",
    "del dirname, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4813a93d-3cfc-4c20-bce1-13cdf82f5e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
