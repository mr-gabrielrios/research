{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4406625-6dbb-4b10-bd74-24081be1f989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility imports\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Local imports\n",
    "sys.path.insert(1, '/projects/GEOCLIM/gr7610/scripts')\n",
    "import composite_TC, track_TC_GCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a8a317-fe70-4986-bd65-76db7d2b557c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def check_climatology_exists(model_name: str,\n",
    "                             experiment_name: str,\n",
    "                             field_name: str,\n",
    "                             year_range: tuple[int, int],\n",
    "                             pressure_level: int|None=None,\n",
    "                             domain: str='atmos',\n",
    "                             diagnostic: bool=False):\n",
    "\n",
    "    ''' \n",
    "    Make sure a daily climatology exists for the model-experiment configuration in question. \n",
    "    Stops function execution if no climatological data are found.\n",
    "    '''\n",
    "\n",
    "    diagnostic_tag = '[check_climatology_exists()]'\n",
    "\n",
    "    # Correct pressure level if None\n",
    "    pressure_level = 'full' if pressure_level is None else pressure_level\n",
    "    # Storage directory for climatological data\n",
    "    storage_dirname = '/tigress/GEOCLIM/gr7610/analysis/model_out/'\n",
    "    # Define the substring used to search for matching data in the storage directory\n",
    "    search_substr = f'model_{model_name}-exp_{experiment_name}-type_{domain}-var_{field_name}-mean_daily-resample-{pressure_level}'\n",
    "\n",
    "    # Helper function to check start and end years [filename minimum (maximum) should be less than (greater than) or equal to requested years]\n",
    "    check_years = lambda x: (int(x.split('-')[-1].split('.')[0].split('_')[0]) <= min(year_range)) and (int(x.split('-')[-1].split('.')[0].split('_')[1]) >= max(year_range))\n",
    "    # Check if file exists in the directory\n",
    "    filenames = [f for f in os.listdir(storage_dirname)\n",
    "                 if search_substr in f \n",
    "                 and f.endswith('.nc')\n",
    "                 and check_years(f)]\n",
    "\n",
    "    if diagnostic:\n",
    "        print(f'{diagnostic_tag} filenames found: {filenames}')\n",
    "\n",
    "    assert len(filenames) == 1, f'{diagnostic_tag} Multiple or insufficient filenames for model {model_name}, experiment {experiment_name}, field name {field_name} found: {filenames}. Please check the year ranges and remove any duplicate files as needed.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51f92960-e014-41d4-bd1a-ed2f5cacf499",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def check_track_data_exists(model_name: str,\n",
    "                            experiment_name: str,\n",
    "                            year_range: tuple[int, int],\n",
    "                            diagnostic: bool=False):\n",
    "\n",
    "    ''' \n",
    "    Make sure track data for the model-experiment configuration in question. \n",
    "    Stops function execution if no track data are found.\n",
    "    '''\n",
    "\n",
    "    diagnostic_tag = '[check_track_data_exists()]'\n",
    "\n",
    "    # Storage directory for track data\n",
    "    storage_dirname = '/projects/GEOCLIM/gr7610/analysis/tc_storage/track_data'\n",
    "    # Define the substring used to search for matching data in the storage directory\n",
    "    search_substr = f'model_{model_name}.experiment_{experiment_name}'\n",
    "\n",
    "    # Helper function to check start and end years [filename minimum (maximum) should be less than (greater than) or equal to requested years]\n",
    "    check_years = lambda x: (int(x.split('.')[1].split('_')[0][1:]) <= min(year_range)) and (int(x.split('.')[1].split('_')[1][1:]) >= max(year_range))\n",
    "    # Check if file exists in the directory\n",
    "    filenames = [f for f in os.listdir(storage_dirname)\n",
    "                 if search_substr in f \n",
    "                 and f.endswith('.pkl') \n",
    "                 and check_years(f)]\n",
    "\n",
    "    if diagnostic:\n",
    "        print(f'{diagnostic_tag} filenames found: {filenames}')\n",
    "\n",
    "    assert len(filenames) == 1, f'{diagnostic_tag} Multiple or insufficient filenames for model {model_name}, experiment {experiment_name}, field name {field_name} found: {filenames}. Please check the year ranges and remove any duplicate files as needed.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ca81bd7-0177-4742-ac4c-b66cd9684410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_TC_GCM_data(model_name: str,\n",
    "                         experiment_name: str,\n",
    "                         year_range: tuple[int, int],\n",
    "                         GCM_data_type: str='atmos_4xdaily',\n",
    "                         number_of_TCs: int=25,\n",
    "                         override_user_input: bool=False,\n",
    "                         diagnostic: bool=False):\n",
    "    \n",
    "    ''' Method to generate GCM output corresponding to TCs for a given model-experiemnt configuration. '''\n",
    "\n",
    "    importlib.reload(track_TC_GCM)\n",
    "    diagnostic_tag = '[generate_TC_GCM_data()]'\n",
    "\n",
    "    # TC generation parameters\n",
    "    intensity_parameter = 'min_slp'\n",
    "    number_of_storms = 25\n",
    "    intensity_range = (0, 1000)\n",
    "    latitude_range = (-40, 40)\n",
    "    storage_dirname = '/projects/GEOCLIM/gr7610/analysis/TC-AQP/data/individual_TCs'\n",
    "    \n",
    "    # Check how many TCs are currently saved. \n",
    "    # If below `threshold_TC_count`, generate automatically. Else, prompt the user.\n",
    "    \n",
    "    generate_new_TCs = False # boolean to determine if new TCs will be generated\n",
    "    threshold_TC_count = 50 # minimum number of TCs needed for adequate compositing sample\n",
    "    config_TC_substr = f'TC.model-{model_name}.experiment-{experiment_name}' # substring used to search for configuration-specific TCs\n",
    "    filenames_TCs = [f for f in os.listdir(storage_dirname)\n",
    "                     if config_TC_substr in f \n",
    "                     and f.endswith('.nc')]\n",
    "    # Determine if new TCs will be generated\n",
    "    if len(filenames_TCs) > threshold_TC_count and not override_user_input:\n",
    "        prompt = input(f'{diagnostic_tag} {len(filenames_TCs)} TCs currently have data generated for configuration {model_name}-{experiment_name}. Should additional data be generated? (y/n)')\n",
    "        generate_new_TCs = True if 'y' in prompt.lower() else False\n",
    "    else:\n",
    "        generate_new_TCs = True\n",
    "\n",
    "    # Generate new GCM data corresponding to tracked TCs for the iterand configuration\n",
    "    if generate_new_TCs:\n",
    "        track_data = track_TC_GCM.main(model_name=model_name, \n",
    "                                       experiment_name=experiment_name,\n",
    "                                       year_range=year_range, \n",
    "                                       intensity_parameter=intensity_parameter, \n",
    "                                       intensity_range=intensity_range, \n",
    "                                       latitude_range=latitude_range,\n",
    "                                       number_of_storms=number_of_storms,\n",
    "                                       GCM_data_type=GCM_data_type,\n",
    "                                       storage_dirname=storage_dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "876eae49-c80e-481e-b70c-711bcd19d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_TC_composites(model_name: str,\n",
    "                           experiment_name: str,\n",
    "                           year_range: tuple[int, int],\n",
    "                           field_name: str,\n",
    "                           number_of_snapshots: int,\n",
    "                           diagnostic: bool=False):\n",
    "    \n",
    "    importlib.reload(composite_TC)\n",
    "    intensity_parameter = 'min_slp'\n",
    "    intensity_range = (0, 1000)\n",
    "    compositing_mode = 'anomaly'\n",
    "    save_data = True\n",
    "    storage_dirname = '/projects/GEOCLIM/gr7610/analysis/TC-AQP/data/composite'\n",
    "\n",
    "    composite_config_name = f'{model_name}-{experiment_name}'\n",
    "    composite_TC.main(configuration_name=composite_config_name,\n",
    "                      field_name=field_name,\n",
    "                      year_range=year_range,\n",
    "                      intensity_parameter=intensity_parameter,\n",
    "                      intensity_range=intensity_range,\n",
    "                      number_of_snapshots=number_of_snapshots,\n",
    "                      compositing_mode=compositing_mode,\n",
    "                      save_data=save_data,\n",
    "                      parallel=True,\n",
    "                      TC_source_dirname='/projects/GEOCLIM/gr7610/analysis/TC-AQP/data/individual_TCs',\n",
    "                      storage_dirname=storage_dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9faac77c-b3c7-4370-aa56-fe96f361e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(configuration_name: str,\n",
    "         year_range: tuple[int, int],\n",
    "         field_name: str,\n",
    "         GCM_data_type: str='atmos_4xdaily',\n",
    "         pressure_level: str|None=None,\n",
    "         number_of_snapshots: int=50,\n",
    "         processing_mode: str='generate_TC_GCM_data',\n",
    "         diagnostic: bool=False):\n",
    "\n",
    "    assert processing_mode in ['generate_TC_GCM_data', 'generate_TC_GCM_composites'], f\"Processing mode must be one of ['generate_TC_GCM_data', 'generate_TC_GCM_composites']. \"\n",
    "    if diagnostic:\n",
    "        print(f'Processing composite anomalies for configuration {configuration_name} for field {field_name}...')\n",
    "    \n",
    "    # Get model and experiment name\n",
    "    assert len(configuration_name.split(':')) == 2, 'Configuration name must be of format {MODEL_NAME}:{EXPERIMENT_NAME}.'\n",
    "    model_name, experiment_name = configuration_name.split(':')\n",
    "\n",
    "    # 1. Check that track data for the configuration exists\n",
    "    check_track_data_exists(model_name=model_name, \n",
    "                            experiment_name=experiment_name, \n",
    "                            year_range=year_range,\n",
    "                            diagnostic=diagnostic)\n",
    "\n",
    "    # 2. Generate TC-tracking GCM output for the iterand configuration\n",
    "    generate_TC_GCM_data(model_name=model_name, \n",
    "                         experiment_name=experiment_name, \n",
    "                         year_range=year_range,\n",
    "                         GCM_data_type=GCM_data_type,\n",
    "                         number_of_TCs=number_of_snapshots,\n",
    "                         diagnostic=diagnostic)\n",
    "\n",
    "    if processing_mode == 'generate_TC_GCM_composites':\n",
    "\n",
    "        # 3. Check if the climatology for the configuration exists\n",
    "        check_climatology_exists(model_name=model_name, \n",
    "                                 experiment_name=experiment_name, \n",
    "                                 year_range=year_range, \n",
    "                                 field_name=field_name, \n",
    "                                 pressure_level=pressure_level,\n",
    "                                 diagnostic=diagnostic)\n",
    "\n",
    "        # 4. Perform anomaly compositing for a given model-experiment configuration\n",
    "        generate_TC_composites(model_name=model_name,\n",
    "                               experiment_name=experiment_name,\n",
    "                               year_range=year_range,\n",
    "                               field_name=field_name,\n",
    "                               number_of_snapshots=number_of_snapshots,\n",
    "                               diagnostic=diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "796d0667-22d9-423c-a4fc-9987695a4f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Processing WVP for HIRAM:CTL1990.15N...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "[generate_TC_GCM_data()] 166 TCs currently have data generated for configuration HIRAM-CTL1990.15N. Should additional data be generated? (y/n) n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing composites for HIRAM, CTL1990.15N over years (2, 16)...\n",
      "[load_track_data()] Number of unique storms in track dataset: 3008\n",
      "[filter_track_data()] Number of unique storms in filtered track dataset: 166\n",
      "[get_snapshots_from_track_data()] Number of snapshots: 4000; number of track dataset entries: 5817\n",
      "Warning: this snapshot group risks having too little diversity in unique TCs with 166 unique TCs in 4000 snapshots.\n",
      "Number of snapshots in container: 4000\n",
      "Time elapsed for TCs: 44.95 s; per snapshot: 0.01 s.\n",
      "Time elapsed for GCM data: 1039.48 s; per snapshot: 0.26 s.\n",
      "Saving composite data to /projects/GEOCLIM/gr7610/analysis/TC-AQP/data/composite/TC.configuration.HIRAM-CTL1990.15N.field_name.WVP.year_range.2_16.intensity_range.0_1000.basin.global.nc...\n",
      "Saving composite data to /projects/GEOCLIM/gr7610/analysis/TC-AQP/data/composite/GCM.configuration.HIRAM-CTL1990.15N.field_name.WVP.year_range.2_16.intensity_range.0_1000.basin.global.nc...\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(track_TC_GCM)\n",
    "\n",
    "processing_mode = 'generate_TC_GCM_composites'\n",
    "field_names = ['WVP'] \n",
    "configurations = {'HIRAM:CTL1990.15N': {'year_range': (2, 16), 'number_of_snapshots': 4000}}\n",
    "\n",
    "for configuration_name in configurations.keys():\n",
    "    for field_name in field_names:\n",
    "        print('==========================================================================================')\n",
    "        print(f'Processing {field_name} for {configuration_name}...')\n",
    "        main(configuration_name=configuration_name,\n",
    "             year_range=configurations[configuration_name]['year_range'],\n",
    "             field_name=field_name,\n",
    "             processing_mode=processing_mode,\n",
    "             GCM_data_type='atmos_4xdaily',\n",
    "             number_of_snapshots=configurations[configuration_name]['number_of_snapshots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b0150-fccf-4017-9037-819357cf7660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
